{"default_analyzer": "# /// script\n# dependencies = [\n#    \"arviz>=0.22.0\",\n#    \"bokeh==3.7.3\",\n#    \"requests>=2.32.4\",\n#    \"ruamel-yaml\",\n# ]\n# ///\n\nimport arviz as az\nfrom Coinfer import (\n    render_plots_to_html,\n    save_result,\n    current_workflow,\n)\nimport numpy as np\n\ncommon_plot_params = {\n    \"backend\": \"bokeh\",\n    \"show\": False,\n}\n\n\ndef plot_autocorr(xp):\n    ret = []\n    for chain in xp.all_chains():\n        chain_inference_data = xp.inference_data[chain]\n        ret.append(('plot_autocorr', chain, \"\", az.plot_autocorr(chain_inference_data, **common_plot_params)))\n    return ret\n\n\ndef plot_ecdf(xp):\n    ret = []\n    for chain in xp.all_chains():\n        chain_inference_data = xp.inference_data[chain]\n        for var in xp.all_vars():\n            values = chain_inference_data.posterior.sel(chain=chain)[var].values\n            if values.dtype == np.bool:\n                continue\n            ret.append(('plot_ecdf', chain, var, az.plot_ecdf(values=values, **common_plot_params)))\n    return ret\n\n\ndef plot_dist(xp):\n    ret = []\n    for chain in xp.all_chains():\n        chain_inference_data = xp.inference_data[chain]\n        for var in xp.all_vars():\n            values = chain_inference_data.posterior.sel(chain=chain)[var].values\n            if values.dtype == np.bool:\n                continue\n            ret.append(('plot_dist', chain, var, az.plot_dist(values=values, **common_plot_params)))\n    return ret\n\n\ndef plot_dot(xp):\n    ret = []\n    for chain in xp.all_chains():\n        chain_inference_data = xp.inference_data[chain]\n        for var in xp.all_vars():\n            values = chain_inference_data.posterior.sel(chain=chain)[var].values\n            if values.dtype == np.bool:\n                continue\n            ret.append(('plot_dot', chain, var, az.plot_dot(values=values, **common_plot_params)))\n    return ret\n\n\ndef analyzer(xp):\n    plots = [\n        *plot_autocorr(xp),\n        # *plot_ecdf(xp),\n        # *plot_dist(xp),\n        # *plot_dot(xp),\n    ]\n    html = render_plots_to_html(plots)\n    return html.encode('utf-8')\n\n\ndef main():\n    flow = current_workflow()\n    exp = flow.experiment\n    save_result(analyzer(exp), \"output.html\")\n\n\nif __name__ == '__main__':\n    main()", "default_data": "\"height\";\"weight\";\"age\";\"male\"\n151.765;47.8256065;63;1\n139.7;36.4858065;63;0\n136.525;31.864838;65;0\n156.845;53.0419145;41;1\n145.415;41.276872;51;0\n163.83;62.992589;35;1\n149.225;38.2434755;32;0\n168.91;55.4799715;27;1\n147.955;34.869885;19;0", "default_data_script": "# /// script\n# dependencies = [\n#   \"pandas\",\n#   \"numpy\",\n#   \"bokeh\",\n#   \"requests\",\n#   \"ruamel-yaml\",\n# ]\n# ///\n\nimport pandas as pd\nimport numpy as np\nfrom io import StringIO\nfrom Coinfer import current_workflow\n\n\ndef interpret_data(data):\n    df = pd.read_csv(StringIO(data.decode(\"utf-8\")), delimiter=';')\n    df = df[df['age'] >= 18]\n    # The return value must be json serializable and will be used as model parameters:w\n    return [df['height'].to_list()]\n\nflow = current_workflow()\nflow.parse_data(interpret_data)", "default_model": "using Pkg\nPkg.develop(; path=ARGS[1])  # load Coinfer.jl\nPkg.add(\"Turing\")\n\nusing Turing\nusing Coinfer\n\nflow = Coinfer.current_workflow()\n\n@model function line(height)\n    \u03bc ~ Normal(178, 20)\n    \u03c3 ~ Uniform(0, 50)\n\n    height ~ Normal(\u03bc, \u03c3)\nend\n\nflow.model = line", "default_startup_script": "using StableRNGs\nusing AbstractMCMC\n\nflow = Coinfer.current_workflow()\nm = flow.model(flow.parsed_data...)\n\nparallel_algorithm = Meta.parse(flow.settings[\"sampling\"][\"parallel_algorithm\"]) |> eval\niteration_count = flow.settings[\"sampling\"][\"iteration_count\"]\nnum_chains = flow.settings[\"sampling\"][\"num_chains\"]\n\nCoinfer.sample(\n    StableRNG(Int(floor(time()))),\n    m,\n    NUTS(),\n    parallel_algorithm,\n    iteration_count,\n    num_chains;\n)", "default_workflow_settings": "coinfer:\n  experiment_name: \"__EXPERIMENT_NAME__\"\n\nserverless:\n  engine: \"fargate\"  # fargate/lambda\n  env_cache: s3://julia-instantiate-cache\n  parallel: 1\n\nsampling:\n  parallel_algorithm: \"AbstractMCMC.MCMCSerial()\"  # AbstractMCMC.MCMCThreads() or AbstractMCMC.MCMCDistributed()\n  iteration_count: 1000\n  num_chains: 1\n  mcmc_data:\n    directory: mcmcdata/\n  ppl: turing\n  # arguments to Julia executable:\n  #   If you use MCMCThreads, you need to add the correct `-t x` where x is the number of threads.\n  #   If you use MCMCDistributed, you need to add the correct `-p x` where x is the number of processes.\n  julia_args: []\n  sync: coinfer\n\nanalysis:\n  output_dir: ./analyzer_output/\n  sync: coinfer", "google_app_id": "versatile-blend-464708-a0", "google_client_id": "1093329952197-v3oe8gknfun6m13r8a111286pk5kcvd4.apps.googleusercontent.com", "max_upload_sample_file": 4, "max_upload_sample_size": 5242880, "run_model_url": "https://y3aioqhakwsvvagglrpvpaoori0hjbor.lambda-url.us-west-2.on.aws/", "upload_file_types": "{\"csv\": [\"turing csv\", \"stan csv\"], \"nc\": [\"arviz netcdf\"]}", "websocket": "wss://wsspr2.coinfer.ai"}