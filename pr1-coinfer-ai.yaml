auth0_client_id: 1JnzhLTbBIelYCQz9jiDa3tDLsvhgJ0A
auth0_domain: login.coinfer.ai
default_analyzer: |-
  # /// script
  # dependencies = [
  #    "arviz>=0.22.0",
  #    "bokeh==3.7.3",
  #    "requests>=2.32.4",
  #    "ruamel-yaml",
  # ]
  # ///

  import arviz as az
  from Coinfer import (
      render_plots_to_html,
      save_result,
      current_workflow,
  )
  import numpy as np

  common_plot_params = {
      "backend": "bokeh",
      "show": False,
  }


  def plot_autocorr(xp):
      ret = []
      for chain in xp.all_chains():
          chain_inference_data = xp.inference_data[chain]
          ret.append(('plot_autocorr', chain, "", az.plot_autocorr(chain_inference_data, **common_plot_params)))
      return ret


  def plot_ecdf(xp):
      ret = []
      for chain in xp.all_chains():
          chain_inference_data = xp.inference_data[chain]
          for var in xp.all_vars():
              values = chain_inference_data.posterior.sel(chain=chain)[var].values
              if values.dtype == np.bool:
                  continue
              ret.append(('plot_ecdf', chain, var, az.plot_ecdf(values=values, **common_plot_params)))
      return ret


  def plot_dist(xp):
      ret = []
      for chain in xp.all_chains():
          chain_inference_data = xp.inference_data[chain]
          for var in xp.all_vars():
              values = chain_inference_data.posterior.sel(chain=chain)[var].values
              if values.dtype == np.bool:
                  continue
              ret.append(('plot_dist', chain, var, az.plot_dist(values=values, **common_plot_params)))
      return ret


  def plot_dot(xp):
      ret = []
      for chain in xp.all_chains():
          chain_inference_data = xp.inference_data[chain]
          for var in xp.all_vars():
              values = chain_inference_data.posterior.sel(chain=chain)[var].values
              if values.dtype == np.bool:
                  continue
              ret.append(('plot_dot', chain, var, az.plot_dot(values=values, **common_plot_params)))
      return ret


  def analyzer(xp):
      plots = [
          *plot_autocorr(xp),
          # *plot_ecdf(xp),
          # *plot_dist(xp),
          # *plot_dot(xp),
      ]
      html = render_plots_to_html(plots)
      return html.encode('utf-8')


  def main():
      flow = current_workflow()
      exp = flow.experiment
      save_result(analyzer(exp), "output.html")


  if __name__ == '__main__':
      main()
default_data: |-
  "height";"weight";"age";"male"
  151.765;47.8256065;63;1
  139.7;36.4858065;63;0
  136.525;31.864838;65;0
  156.845;53.0419145;41;1
  145.415;41.276872;51;0
  163.83;62.992589;35;1
  149.225;38.2434755;32;0
  168.91;55.4799715;27;1
  147.955;34.869885;19;0
default_data_script: |-
  # /// script
  # dependencies = [
  #   "pandas",
  #   "numpy",
  #   "bokeh",
  #   "requests",
  #   "ruamel-yaml",
  # ]
  # ///

  import pandas as pd
  import numpy as np
  from io import StringIO
  from Coinfer import current_workflow


  def interpret_data(data):
      df = pd.read_csv(StringIO(data.decode("utf-8")), delimiter=';')
      df = df[df['age'] >= 18]
      # The return value must be json serializable and will be used as model parameters:w
      return [df['height'].to_list()]

  flow = current_workflow()
  flow.parse_data(interpret_data)
default_model: "using Pkg\nPkg.develop(; path=ARGS[1])  # load Coinfer.jl\nPkg.add(\"\
  Turing\")\n\nusing Turing\nusing Coinfer\n\nflow = Coinfer.current_workflow()\n\n\
  @model function line(height)\n    \u03BC ~ Normal(178, 20)\n    \u03C3 ~ Uniform(0,\
  \ 50)\n\n    height ~ Normal(\u03BC, \u03C3)\nend\n\nflow.model = line"
default_startup_script: |-
  using StableRNGs
  using AbstractMCMC

  flow = Coinfer.current_workflow()
  m = flow.model(flow.parsed_data...)

  parallel_algorithm = Meta.parse(flow.settings["sampling"]["parallel_algorithm"]) |> eval
  iteration_count = flow.settings["sampling"]["iteration_count"]
  num_chains = flow.settings["sampling"]["num_chains"]

  Coinfer.sample(
      StableRNG(Int(floor(time()))),
      m,
      NUTS(),
      parallel_algorithm,
      iteration_count,
      num_chains;
  )
default_workflow_settings: |-
  coinfer:
    experiment_name: "__EXPERIMENT_NAME__"

  serverless:
    engine: "fargate"  # fargate/lambda
    env_cache: s3://julia-instantiate-cache
    parallel: 1

  sampling:
    parallel_algorithm: "AbstractMCMC.MCMCSerial()"  # AbstractMCMC.MCMCThreads() or AbstractMCMC.MCMCDistributed()
    iteration_count: 1000
    num_chains: 1
    mcmc_data:
      directory: mcmcdata/
    ppl: turing
    # arguments to Julia executable:
    #   If you use MCMCThreads, you need to add the correct `-t x` where x is the number of threads.
    #   If you use MCMCDistributed, you need to add the correct `-p x` where x is the number of processes.
    julia_args: []
    sync: coinfer

  analysis:
    output_dir: ./analyzer_output/
    sync: coinfer
google_app_id: versatile-blend-464708-a0
google_client_id: 1093329952197-v3oe8gknfun6m13r8a111286pk5kcvd4.apps.googleusercontent.com
max_upload_sample_file: 4
max_upload_sample_size: 5242880
run_model_url: https://07ka4n4yna.execute-api.us-west-2.amazonaws.com/prod
upload_file_types: '{"csv": ["turing csv", "stan csv"], "nc": ["arviz netcdf"]}'
websocket: wss://wsspr1.coinfer.ai
